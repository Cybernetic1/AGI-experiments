"""
Download TinyStories dataset (subset for CPU training).

TinyStories is a collection of short stories generated by GPT-3.5/4
with simple vocabulary and grammar, designed for training small language models.

- More realistic than bAbI (natural language)
- Still simple enough for CPU training
- Good entity tracking and narrative structure
"""
from datasets import load_dataset
import json
from pathlib import Path
from tqdm import tqdm


def download_subset(num_stories: int = 10000):
    """Download a subset of TinyStories."""
    
    print(f"Downloading {num_stories} stories from TinyStories...")
    
    # Load dataset in streaming mode (memory efficient)
    ds = load_dataset('roneneldan/TinyStories', split='train', streaming=True)
    
    stories = []
    for i, example in enumerate(tqdm(ds, total=num_stories, desc="Downloading")):
        if i >= num_stories:
            break
        stories.append(example['text'])
    
    # Save to file
    output_dir = Path("data/tinystories")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    with open(output_dir / f"stories_{num_stories}.txt", 'w') as f:
        for story in stories:
            f.write(story + "\n\n---STORY_SEPARATOR---\n\n")
    
    print(f"\n✓ Saved {len(stories)} stories to {output_dir / f'stories_{num_stories}.txt'}")
    
    # Stats
    total_chars = sum(len(s) for s in stories)
    avg_length = total_chars / len(stories)
    
    print(f"\nStatistics:")
    print(f"  Total stories: {len(stories)}")
    print(f"  Total characters: {total_chars:,}")
    print(f"  Avg story length: {avg_length:.0f} chars")
    print(f"  Estimated sentences: ~{total_chars // 100:,}")
    
    # Show sample
    print(f"\nSample story:")
    print("=" * 60)
    print(stories[5][:400] + "...")
    print("=" * 60)
    
    return stories


if __name__ == "__main__":
    # Download 10K stories (enough for realistic training, manageable on CPU)
    stories = download_subset(num_stories=10000)
    
    print("\n✓ Download complete!")
    print("\nNext steps:")
    print("  1. Preprocess stories to extract propositions")
    print("  2. Build entity registry from natural text")
    print("  3. Train VQ-VAE on real narrative patterns")
    print("  4. Train AR model on longer, more varied sequences")
